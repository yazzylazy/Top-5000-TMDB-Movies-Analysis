{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSI 4142 Deliverable 2 - Phase 2\n",
    "### Group 35\n",
    "- Yasin Elmi, 300163765\n",
    "- Oluwatobiloba Ogunbi, 300202843\n",
    "- Michael Thompson, 300175414"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intial reading of files into dataframes\n",
    "\n",
    "Note: may need to adjust the file name and/or location if this notebook is not within the same directory as the data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df_movies = pd.read_csv('datasets/tmdb_5000_movies.csv', index_col=False)\n",
    "df_credits = pd.read_csv('datasets/tmdb_5000_movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming of data\n",
    "The following section is the process of our data being cleaned and transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping columns\n",
    "Initial dropping of unnecessary columns, according to our first deliverable plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unneccessary columns\n",
    "df_movies = df_movies.drop('homepage', axis=1)\n",
    "#df_movies = df_movies.drop('id', axis=1)\n",
    "df_movies = df_movies.drop('keywords', axis=1)\n",
    "df_movies = df_movies.drop('overview', axis=1)\n",
    "df_movies = df_movies.drop('status', axis=1)\n",
    "df_movies = df_movies.drop('tagline', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping rows\n",
    "We will begin by initially dropping rows where both the 'budget' and 'revenue' value are 0 (previously determined that there exists no null values in these columns). Both of these values are pertinent to our investigation, and it would be inappropriate to assign an estimated or calculated value for both of these columns. Thus, in the case of our investigatin, we will drop these rows (890 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4803\n",
      "3913\n"
     ]
    }
   ],
   "source": [
    "# Dropping all rows where both the budget and revenue column are 0\n",
    "# These values being 0 present no value to our investigation, and would be filled with \n",
    "print(len(df_movies))\n",
    "index_revenue_budget = df_movies[ (df_movies['revenue']==0) & (df_movies['budget']==0) ].index\n",
    "df_movies = df_movies.drop(index_revenue_budget)\n",
    "print(len(df_movies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null\n",
    "Below we check for rows that are null. In our case, there are only two null values that are present found in the 'runtime' column. Since it isn't appropriate to assume or calculate a potential runtime based on other movies, we will assign all movies with runtime 'Nan' or '0' as -1. Thus, during our investigations we are aware of the incomplete data present for consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>15000000</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}]</td>\n",
       "      <td>370980</td>\n",
       "      <td>it</td>\n",
       "      <td>Chiamatemi Francesco - Il Papa della gente</td>\n",
       "      <td>0.738646</td>\n",
       "      <td>[{\"name\": \"Taodue Film\", \"id\": 45724}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"IT\", \"name\": \"Italy\"}]</td>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}]</td>\n",
       "      <td>Chiamatemi Francesco - Il Papa della gente</td>\n",
       "      <td>7.3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140</th>\n",
       "      <td>2</td>\n",
       "      <td>[{\"id\": 99, \"name\": \"Documentary\"}]</td>\n",
       "      <td>459488</td>\n",
       "      <td>en</td>\n",
       "      <td>To Be Frank, Sinatra at 100</td>\n",
       "      <td>0.050625</td>\n",
       "      <td>[{\"name\": \"Eyeline Entertainment\", \"id\": 60343}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"}]</td>\n",
       "      <td>2015-12-12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>To Be Frank, Sinatra at 100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        budget                               genres      id original_language  \\\n",
       "2656  15000000        [{\"id\": 18, \"name\": \"Drama\"}]  370980                it   \n",
       "4140         2  [{\"id\": 99, \"name\": \"Documentary\"}]  459488                en   \n",
       "\n",
       "                                  original_title  popularity  \\\n",
       "2656  Chiamatemi Francesco - Il Papa della gente    0.738646   \n",
       "4140                 To Be Frank, Sinatra at 100    0.050625   \n",
       "\n",
       "                                  production_companies  \\\n",
       "2656            [{\"name\": \"Taodue Film\", \"id\": 45724}]   \n",
       "4140  [{\"name\": \"Eyeline Entertainment\", \"id\": 60343}]   \n",
       "\n",
       "                                  production_countries release_date  revenue  \\\n",
       "2656           [{\"iso_3166_1\": \"IT\", \"name\": \"Italy\"}]   2015-12-03        0   \n",
       "4140  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"}]   2015-12-12        0   \n",
       "\n",
       "      runtime                               spoken_languages  \\\n",
       "2656      NaN  [{\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}]   \n",
       "4140      NaN                                             []   \n",
       "\n",
       "                                           title  vote_average  vote_count  \n",
       "2656  Chiamatemi Francesco - Il Papa della gente           7.3          12  \n",
       "4140                 To Be Frank, Sinatra at 100           0.0           0  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for other Null or NaN values\n",
    "df_movies[df_movies.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for 'Noisy' values\n",
    "Below is an investigation on 'noisy' values, which appear to be empty cells assigned some place holder value. They are as follows\n",
    "- 147 rows with df_movies['budget'] = 0\n",
    "- 4 rows with df_movies['genres'] = '[]' (placeholder for an empty cell)\n",
    "- 0 rows with df_movies['original_language'] = ''\n",
    "- 0 rows with df_movies['original_title'] = ''\n",
    "- 0 rows with df_movies['popularity'] = 0\n",
    "- 100 rows with df_movies['production_companies'] = '[]' (placeholder for an empty cell)\n",
    "- 47 rows with df_movies['production_countries'] = '[]' (placeholder for an empty cell)\n",
    "- 537 rows with df_movies['revenue'] = 0\n",
    "- 0 rows with df_movies['title'] = ''\n",
    "- 3 rows with df_movies['runtime'] = 0 + 2 rows with df_movies['runtime'] = NaN (as detailed above)\n",
    "- 166 rows where the df_movies['original_title'] != df_movies['title']. This can be assumed that foreign films have an original title name different than it's English title. This is useful to know, as when staging we will utilize the 'title' column and not the 'original_title'.\n",
    "- 11 rows with df_movies['vote_average'] = 0\n",
    "- 11 rows with df_movies['vote_count'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Rows where budget=0: 147\n",
      "# Rows where genres='[]': 4\n",
      "# Rows where original_language='': 0\n",
      "# Rows where original_title='': 0\n",
      "# Rows where popularity=0.0: 0\n",
      "# Rows where production_companies='[]': 100\n",
      "# Rows where production_countries='[]': 47\n",
      "# Rows where revenue=0: 537\n",
      "# Rows where title='': 0\n",
      "# Rows where runtime=0: 3\n",
      "# Rows where title != original_title: 166\n",
      "# Rows where vote_average=0.0: 11\n",
      "# Rows where vote_count=0: 11\n"
     ]
    }
   ],
   "source": [
    "# 1037 rows with 'budget' = 0\n",
    "    # We can use median\n",
    "# 28 rows with 'genre' = ''\n",
    "    # Use special value 'Unknown'\n",
    "# 351 rows with 'production_companies' = ''\n",
    "    # Use special value 'Independent'\n",
    "# 174 rows with 'production_countries' = ''\n",
    "    # Use special value 'Unknown'\n",
    "# 35 rows with 'runtime' = 0 AND 2 rows with 'runtime' = NaN\n",
    "    # Use special value -1\n",
    "# 1427 rows with revenue = 0\n",
    "    # Check median and mean value of 'revenue' column, select which one appears to be more appropriate \n",
    "# 1 row with popularity = 0 (I think this is safe - unpopular movie?)\n",
    "    # keep this value\n",
    "# 63 rows with vote_average = 0.0\n",
    "    # Leave this value 0, as it is possible these movies have received no votes and thus no average can be made (avg of 0 is 0)\n",
    "# 62 rows with vote_count = 0\n",
    "    # Leave this value 0, as it is possible these movies have received no votes on the site\n",
    "\n",
    "\n",
    "# 261 rows where original title != title (Thinking foreign films?)\n",
    "\n",
    "\n",
    "print(\"# Rows where budget=0: \" + str(len(df_movies.loc[df_movies['budget']==0])))\n",
    "print(\"# Rows where genres='[]': \" + str(len(df_movies.loc[df_movies['genres']=='[]'])))\n",
    "print(\"# Rows where original_language='': \" + str(len(df_movies.loc[df_movies['original_language']==''])))\n",
    "print(\"# Rows where original_title='': \" + str(len(df_movies.loc[df_movies['original_title']==''])))\n",
    "print(\"# Rows where popularity=0.0: \" + str(len(df_movies.loc[df_movies['popularity']==0.0])))\n",
    "print(\"# Rows where production_companies='[]': \" + str(len(df_movies.loc[df_movies['production_companies']=='[]'])))\n",
    "print(\"# Rows where production_countries='[]': \" + str(len(df_movies.loc[df_movies['production_countries']=='[]'])))\n",
    "print(\"# Rows where revenue=0: \" + str(len(df_movies.loc[df_movies['revenue']==0])))\n",
    "print(\"# Rows where title='': \" + str(len(df_movies.loc[df_movies['title']==''])))\n",
    "print(\"# Rows where runtime=0: \" + str(len(df_movies.loc[df_movies['runtime']==0])))\n",
    "print(\"# Rows where title != original_title: \" + str(len(df_movies.loc[df_movies['title'] !=df_movies['original_title']])))\n",
    "print(\"# Rows where vote_average=0.0: \" + str(len(df_movies.loc[df_movies['vote_average']==0.0])))\n",
    "print(\"# Rows where vote_count=0: \" + str(len(df_movies.loc[df_movies['vote_count']==0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the 'Noisy' data\n",
    "Below we will be dealing with the noisy data that was identified above.\n",
    "- For df_movies['budget'], we will use the **(median/mean) value** of the column\n",
    "- For df_movies['genres'], we will apply a **special value 'No listed genres'**\n",
    "- For df_movies['production_companies'], we will apply a **special value 'Independent film'**\n",
    "- For df_movies['production_countries'], we will apply a **special value 'Unknown'**\n",
    "- For df_movies['revenue'], we will use the **(median/mean) value** of the column\n",
    "- For df_movies['runtime'], we will apply a **special value -1**\n",
    "- For df_movie['vote_count'] and df_movies['vote_average'], we will refrain from performing any changes as it is possible a movie has no votes thus no vote average\n",
    "- This investigation also identified that the proper title column to utilize is the df_movies['title'] column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here to make the above adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning attributes containing JSON objects as String\n",
    "The 'genre', 'production_companies' and 'production_countries' attributes contain a JSON as a string, which contains a desired key-value pair. A function was created to extract the desired value within the string, and return it as a list.\n",
    "\n",
    "### TODO\n",
    "Some of the rows contain an empty value, denoted by the empty square brackets []. Must decide on how to handle this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the genres, production_companies and production_countries columns from json string\n",
    "\n",
    "def extract_json_key(string, key):\n",
    "    '''\n",
    "    Helper function used to translate string to list of dictionaries, and extract the 'name' key-value pair\n",
    "    (Str, Str) -> Str\n",
    "    Preconditions: None\n",
    "    '''\n",
    "    clean_list = json.loads(string)\n",
    "    name = [x[key] for x in clean_list]\n",
    "    return ', '.join(name)\n",
    "\n",
    "# Calling the above function to extract the respective 'name' key-value \n",
    "df_movies['genres'] = df_movies['genres'].map(lambda x: extract_json_key(x, 'name'))\n",
    "df_movies['production_companies'] = df_movies['production_companies'].map(lambda x: extract_json_key(x, 'name'))\n",
    "df_movies['production_countries'] = df_movies['production_countries'].map(lambda x: extract_json_key(x, 'name'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the language attributes\n",
    "This section is focused on cleaning the two langauge attribtues, 'original_language' and 'spoken_language'. \n",
    "\n",
    "'original_language' is originally written in ISO 639-1 code, which is a 2 letter abbreviation of a word. Using a dictionary found below, the word is swapped for it's verbose display.\n",
    "\n",
    "'spoken_language' is a little more difficult, where a film can have multiple spoken languages. This is stored in a similar JSON string as above which stores both the ISO 639-1 code and the full written word. Unfortunately, the full written word may utilize a unicode character (i.e. 'French' written in French has an accent, which stores a unicode character). The solution to this is utililizing our previously made dictionary and search it using the provided ISO 639-1 code. A function takes the list of JSON objects, extracts the ISO 639-1 code and translates it, then returns.\n",
    "\n",
    "### TODO:\n",
    "- Some of the columns are empty (denoted by an empty set of square brackets []), an example of this is column k row 2650. Need to make decision on how to handle this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary mapping 2 letter language abbrv. to full word\n",
    "language_two_code_dict = {\n",
    "    'en': 'English',\n",
    "    'fr': 'French',\n",
    "    'ja': 'Japanese',\n",
    "    'zh': 'Chinese',\n",
    "    'es': 'Spanish',\n",
    "    'de': 'German',\n",
    "    'hi': 'Hindi',\n",
    "    'ru': 'Russian',\n",
    "    'ko': 'Korean',\n",
    "    'te': 'Telugu',\n",
    "    'cn': 'Chinese',\n",
    "    'it': 'Italian',\n",
    "    'nl': 'Dutch',\n",
    "    'ta': 'Tamil',\n",
    "    'sv': 'Swedish',\n",
    "    'th': 'Thai',\n",
    "    'da': 'Danish',\n",
    "    'xx': 'No Language',\n",
    "    'hu': 'Hungarian',\n",
    "    'cs': 'Czech',\n",
    "    'pt': 'Portuguese',\n",
    "    'is': 'Icelandic',\n",
    "    'tr': 'Turkish',\n",
    "    'nb': 'Norwegian Bokmal',\n",
    "    'af': 'Afrikaans',\n",
    "    'pl': 'Polish',\n",
    "    'he': 'Hebrew',\n",
    "    'ar': 'Arabic',\n",
    "    'vi': 'Vietnamese',\n",
    "    'ky': 'Kyrgyz',\n",
    "    'id': 'Indonesian',\n",
    "    'ro': 'Romanian',\n",
    "    'fa': 'Persian',\n",
    "    'no': 'Norwegian',\n",
    "    'sl': 'Slovenian',\n",
    "    'ps': 'Pashto',\n",
    "    'el': 'Greek'\n",
    "}\n",
    "\n",
    "def language_lookup(word):\n",
    "    '''\n",
    "    Helper function that searches a ISO 639-1 code in the dictionary and returns the verbose word\n",
    "    String -> String\n",
    "    '''\n",
    "    if(word in language_two_code_dict):\n",
    "        return language_two_code_dict.get(word)\n",
    "    else:\n",
    "        return 'NEED TO DOUBLE CHECK MISSING'\n",
    "\n",
    "df_movies['original_language'] = df_movies['original_language'].map(lambda x: language_lookup(x))\n",
    "\n",
    "\n",
    "def translate_and_clean(string):\n",
    "    '''\n",
    "    Helper function that takes string of 2 code abbreviations, translates and returns in a String\n",
    "    (Str) -> Str\n",
    "    '''\n",
    "    extract = extract_json_key(string, 'iso_639_1').split(',')\n",
    "    for i in range(len(extract)):\n",
    "        extract[i] = extract[i].strip()\n",
    "        extract[i] = language_lookup(extract[i])\n",
    "    \n",
    "    return ', '.join(extract)\n",
    "\n",
    "# Apply function on each row within 'spoken_languages' column\n",
    "df_movies['spoken_languages'] = df_movies['spoken_languages'].map(lambda x: translate_and_clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Staging the data\n",
    "Below is the staging part of our script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
